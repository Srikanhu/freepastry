<!DOCTYPE html PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html><head>
  <meta content="text/html; charset=iso-8859-1" http-equiv="Content-Type"><title>FreePastry</title></head><body style="font-family: Verdana,Arial;" alink="#ff0000" bgcolor="#ffffff" link="#0000ee" text="#000000" vlink="#551a8b">
<h2>
<center>
<h1><font size="+4">FreePastry release notes</font></h1>
<hr size="2" width="100%"></center>
</h2>
Release 1.4,&nbsp; 3/15/05.
<p>FreePastry is a modular, open source implementation of the <a href="http://www.cs.rice.edu/CS/Systems/Pastry/"> Pastry</a> p2p routing
and location substrate. <br>
&nbsp; </p>
<h3> Contributors</h3>
<a href="http://www.cs.rice.edu/%7Edruschel/">Peter Druschel</a> , 
Eric Engineer , 
<a href="http://www.cs.rice.edu/%7Ergil">Romer Gil</a> , 
<a href="http://www.cs.rice.edu/%7Eahae/">Andreas Haeberlen</a> , 
<a href="http://www.cs.rice.edu/%7Ejeffh/">Jeff Hoye</a> , 
<a href="http://www.cs.rice.edu/%7Eychu/">Y. Charlie Hu</a> , 
<a href="http://www.cs.rice.edu/%7Essiyer/">Sitaram Iyer</a> , 
<a href="http://www.cs.rice.edu/%7Ealadd/">Andrew Ladd</a> ,
<a href="http://www.cs.rice.edu/%7Eamislove">Alan Mislove</a> , 
<a href="http://www.cs.rice.edu/%7Eanimesh">Animesh Nandi</a> , 
<a href="http://www.cs.rice.edu/%7Eabpost">Ansley Post</a> , 
<a href="http://www.cs.rice.edu/%7Ecreis">Charlie Reis</a> , 
<a href="http://www.cs.rice.edu/%7Edsandler">Dan Sandler</a> ,
<a href="http://www.cs.rice.edu/%7Eatuls">Atul Singh</a> , and 
<a href="http://composer.ecn.purdue.edu/%7Erongmei/">RongMei Zhang</a>
contributed to the FreePastry code. The code is based on algorithms and
protocols described in the following papers: <br>
&nbsp;
<ul>
  <li><font face="Helvetica, Arial, sans-serif">A. Rowstron and P.
Druschel, <i>Pastry: Scalable, distributed object location and routing
for large-scale   peer-to-peer systems</i>.&nbsp; IFIP/ACM International
Conference on Distributed   Systems Platforms (Middleware), Heidelberg,
Germany, pages 329-350, November,   2001. [<i><a href="http://www.research.microsoft.com/%7Eantr/PAST/pastry.pdf.zip">
pdf.zip</a> | <a href="http://www.research.microsoft.com/%7Eantr/PAST/pastry.ps.zip">
ps.zip</a> | <a href="http://www.research.microsoft.com/%7Eantr/PAST/pastry.pdf"> pdf</a>
| <a href="http://www.research.microsoft.com/%7Eantr/PAST/pastry.ps"> ps</a> </i>]</font></li>
</ul>
<ul>
  <li><font face="Helvetica, Arial, sans-serif">M. Castro, P. Druschel,
Y. C. Hu, A. Rowstron, <i>Exploiting network proximity in peer-to-peer
overlay networks</i>.&nbsp; Submitted for publication.&nbsp; [<i><a href="http://www.research.microsoft.com/%7Eantr/PAST/location.pdf.zip">
pdf.zip</a> |<a href="http://www.research.microsoft.com/%7Eantr/PAST/location.ps.zip">
ps.zip</a> | <a href="http://www.research.microsoft.com/%7Eantr/PAST/location.pdf"> pdf</a>
| <a href="http://www.research.microsoft.com/%7Eantr/PAST/location.ps">
ps</a> </i>]</font></li>
</ul>
<ul>
  <li><font face="Helvetica, Arial, sans-serif"> M. Castro, P. Druschel,
 A.-M.  Kermarrec&nbsp; and A. Rowstron, "<i>SCRIBE: A large-scale and
decentralised application-level multicast infrastructure</i>", IEEE
Journal on Selected  Areas  in Communications (JSAC) (Special issue on
Network Support for Multicast   Communications). 2002, to appear.&nbsp; [<i><a href="http://www.research.microsoft.com/%7Eantr/PAST/jsac.pdf.zip">
pdf.zip</a> | <a href="http://www.research.microsoft.com/%7Eantr/PAST/jsac.ps.zip">
ps.zip</a> | <a href="http://www.research.microsoft.com/%7Eantr/PAST/jsac.pdf">pdf</a>
| <a href="http://www.research.microsoft.com/%7Eantr/PAST/jsac.ps">ps</a> </i>
]</font></li>
</ul>
<ul>
  <li><font style="font-family: helvetica,arial,sans-serif;">A.
Rowstron and P. Druschel, "<i>Storage management and caching in PAST, a
large-scale, persistent       peer-to-peer storage utility</i>", 18th
ACM SOSP'01, Lake Louise, Alberta, Canada, October 2001.&nbsp; [<i> <a href="http://www.cs.rice.edu/CS/Systems/PAST/past-sosp.pdf.zip">pdf.zip</a>
| <a href="http://www.cs.rice.edu/CS/Systems/PAST/past-sosp.ps.zip">ps.zip</a>
| <a href="http://www.cs.rice.edu/CS/Systems/PAST/past-sosp.pdf">pdf</a>
| <a href="http://www.cs.rice.edu/CS/Systems/PAST/past-sosp.ps">ps</a> </i>
] (Corrected - erratum for original version: <i>&nbsp;<a href="http://www.cs.rice.edu/CS/Systems/PAST/sosp-erratum.ps">ps</a>)</i></font><br style="font-family: helvetica,arial,sans-serif;">
  </li>
</ul>
<ul>
  <li>
<font style="font-family: helvetica,arial,sans-serif;">
F. Dabek,
P. Druschel, B. Zhao, J. Kubiatowicz, and I. Stoica, "<i>Towards a
Common API for Structured Peer-to-Peer Overlays</i>", 2nd IPTP'03,
Berkeley, CA, February, 2003.&nbsp;
[<i> <a href="http://www.cs.rice.edu/%7Edruschel/publications/kbr-api.pdf">pdf</a></i>
]</font></li>

</ul>
<ul>
<li>
<font style="font-family: helvetica,arial,sans-serif;">
Miguel Castro, Peter Druschel, Anne-Marie Kermarrec, Animesh Nandi, Antony Rowstron and Atul Singh,
<i> SplitStream: High-bandwidth multicast in a cooperative environment. </i>
 In Proceedings of the 19th ACM Symposium on Operating Systems Principles (SOSP'03). Lake George, New York, October 2003.
[<i> <a href="http://freepastry.rice.edu/PAST/SplitStream-results.pdf">pdf </a></i>]
</font>
</li>
</ul>

<br>
<h3>Requirements</h3>
The software requires a Java runtime, version 1.4.2. The software was
developed using Sun's SDK, version 1.4.2_03+ <br>
<br>
&nbsp;<br>
<h3>Changes since release 1.3.2</h3>
<ul>
  <li>Single threaded:&nbsp;
  We have adapted a single threaded model to improve performance. Calls into Pastry are still properly synchronized.  In fact if you run multiple nodes within the same JVM they will execute on the same thread.  The scheduler is implemented in rice.selector.</li><br>

<li>Transport Layer/Routing:</li><br>
<ul>
  <li>Removed rice.pastry.RMI, rice.pastry.Wire -- Use rice.pastry.Socket</li><br>

  <li>Simplified transport layer.  The Socket transport layer uses TCP for <i>all</i> messaging except liveness.</li><br>

  <li>Improved liveness checking, better support for churn.  The Socket transport layer uses UDP only for liveness checks, and they are sent using random exponential backoff.</li><br>
  
  <li>Improved support for PlanetLab and the Internet.  Gracefully handles temporary and permanent routing anomalies by using sourceroutes.  The sourceroutes are selected from nodes within the leafset.</li><br>

  <li>Improved routing performance.  Aggressive routing around nodes that may have stalled.  We now use per hop acks to rapidly route around stalled or congested nodes.</li><br>

  <li>Support for a fixed file descriptor limit on sockets.  This is used for nodes that need to fix the maximum number of concurrently opened sockets.  Typically this is used if you don't have sufficient privilege to raise the maximum number of open file descriptors for a process. (See ulimit -n).</li><br>

  <li>Support for fine grained prioritization of message delivery.  We added <code>int getPriority()</code> to the message interface.  The transport will prioritize higher priority messages over low priority.</li><br>

  <li>Support for multiple bootstrap nodes.  The socket transport layer can take a list of IP addresses to try to boot off of.  It will attempt to connect to them in random order and return the first one it is able to connect to.  (See <code>DistPastryNodeFactory.getNodeHandle(InetSocketAddress[])</code>)</li><br/>

  <li>Support for NodeId reuse.  Previous versions randomized the last 32 bits of a NodeId.  The new version uses an epoch to determine if a node has rebooted since you last talked to it.</li><br/>
</ul>
<li>Modules:</li><br>
<ul>
  <li>p2p.commonapi -- Added priority to messages.</li><br/>
  <li>p2p.past -- Added lease-based past version in p2p.past.gc - extends the PAST interface.</li><br/>
  <li>p2p.scribe -- Minor changes.</li><br/>
  <li>p2p.replication -- This has been modified to use bloom filters instead of key lists for replication.</li><br/>
  <li>p2p.splitstream -- Minor scalability improvements based on planetlab deployment.</li><br>
  <li>(NEW) p2p.util -- Various utilites for p2p packages, including Cryptography and XML.</li><br>
  <li>(NEW) p2p.multiring -- An implementation of the IPTPS paper, complete with optional RingCertificates.</li><br>
  <li>(NEW) p2p.aggregation -- Improves DHT efficiency by aggregating small objects</li><br>
<ul>
<li>Aggregation:  This module can increase the efficiency of a DHT by bundling several small
  objects into a larger aggregate. It is used by Glacier, but can also be
  combined with other DHTs such as PAST. </li><br>
</ul>
  <li>(NEW) p2p.glacier -- Protects against data loss during large-scale correlated failures</li><br>
<ul>
<li>Glacier:  Distributed storage systems can suffer data loss when a large fraction
  of the storage nodes fail simultaneously, e.g. during a worm attack.
  Glacier protects against this by spreading redundant data fragments
  throughout the system. It can reconstruct the data with high probability
  even after disastrous failures that may affect 60% of the nodes or more.
  Please see our NSDI paper on Glacier for a more detailed description.</li><br>
</ul>
  
  <li>persistence -- Many improvements and bug fixes.  Basically the same interface.  Should be now *MUCH* more robust.  Also added metadata support to the rice.persistence package classes.</li><br>
  <li>(NEW) selector -- Allows pastry to run on a single thread.</li><br>
</ul>
</ul>


<h3>Changes since release 1.3.1</h3>
<ul>
  <li>Overhaul of the wire package. The new version is higher
 performance and has eliminated some known synchronization issues that
 can cause deadlock. Furthermore the package produces the more sensible
 NodeIsDeadException if a message is attempted to be sent after the node
 has simulated being killed.  Killing of nodes remains for testing, and is not supported on all platforms.</li>
</ul>
<ul>
  <li>Corrections to past.</li>
</ul>
<ul>
  <li>New version of Replication Manager in rice.p2p.replication.
Based on commonapi instead of pastry. There is an alternate/simpler
interface to rm in the rice.p2p.replication.manager package.</li>
</ul>
<ul>
  <li>Past has been migrated to the new rm (p2p.replication).</li>
</ul>
<ul>
  <li>Some bug fixes.</li>
</ul><br>
<h3>Changes since release 1.3</h3>
<ul>
  <li>New version of Scribe implemented on the common API. New
version
is re-designed to increase the performance, reliability and ease of
use. The previous version of Scribe is still include in the release. </li>
</ul>
<ul>
  <li>New version of PAST provides a method to obtain handles to all
replicas, and various bug fixes. The old version of PAST that was built
on top of the Pastry API is now deprecated.  The version built upon the
commonApi should now be used.
  </li>
</ul>
<ul>
  <li>The discovery protocol for automatic location of nearby node given
any bootstrap node is now implemented. This is described in the <a href="http://freepastry.rice.edu/PAST/location.pdf"> Pastry
proximity paper</a>.
 </li>
</ul>
<ul>
 <li>A prototype implementation of SplitStream, a high bandwidth
multicast system,is now released. This implementation does not yet
implement all of the optimizations described in the paper; therefore,
overheads maybe higher than those reported in the paper. See <a href="#SplitStream">below</a>
for more details about using SplitStream.
 </li>
</ul>
<ul>
  <li>Some bug fixes.</li>
</ul><br>
<h3>Changes since release 1.2</h3>
<ul>
  <li>FreePastry now supports the common API, as described in the
IPTPS'03 paper listed above. Newly developed applications should
use this API, and only import the p2p.commonapi package. The previous,
native FreePastry API continues to be supported for backward
compatibility. <br>
  </li>
</ul>
<ul>
  <li>A more general implementation of the <a href="http://www.cs.rice.edu/CS/Systems/PAST/default.htm">PAST</a>
archival storage system was added in this release. The release adds
support for replication and caching of data.&nbsp;  The implementation
provides a generic distributed hash table (DHT) facility, and allows
control over the semantics of tuple insertion for a given,
application-specific value type. The previous version of PAST has been
marked as deprecated and may not be included in future releases.
Applications that use Past should migrate to the new version. </li>
</ul>
<ul>
  <li>A version of the replication manager, which provides
application-independent management   of replicas, is included.
Application that need to replicate data on the set of <i>n</i> nodes
closest to a given key can use the replication manager in order to
perform this task. </li>
</ul>
<ul>
  <li>Some bug fixes.</li>
</ul>
<br>
<h3>Changes since release 1.1</h3>
<ul>
  <li>A simple implementation of the <a href="http://www.cs.rice.edu/CS/Systems/PAST/default.htm">PAST</a>
archival storage system was added in this release. The implementation
does not currently perform the storage balancing algorithms described in
the SOSP paper, nor does it perform data replication or caching. Support
for replication and caching will be included in the next release.</li>
</ul>
<ul>
  <li>An anycast primitive was added to the implementation of <a href="http://www.research.microsoft.com/%7Eantr/SCRIBE/"> Scribe</a>, a
group communication infrastructure. Also, several methods and new
interfaces and a new interface were added to provide apps more control
over the construction and maintenance of Scribe trees.</li>
</ul>
<ul>
  <li>Some bug fixes.</li>
</ul>
<ul>
  <li>Some initial performance work was done. As a result, large
simulations run about 50% faster, and use a lot less memory.<br>
  </li>
</ul>
<br>
<br>
<h3> Notes</h3>
Release 1.3.2 has the following limitations. <br>
&nbsp;
<ul>
  <li> More performance tuning needs to be done.</li>
&nbsp; <li> Three "transport protocols" are provided with this release,
"Direct", "RMI", and "Wire".</li>
</ul>
<ul>
  <ul>
    <li> "Direct" emulates a network, allowing many Pastry nodes to
execute in one Java VM without a real network. This is very useful for
application development and testing.</li>
  </ul>
</ul>
<ul>
  <ul>
    <li>"RMI" is simple transport protocol based on Java RMI. Several
"virtual" Pastry  nodes can be started in each Java VM. RMI is used for
communication across  physical nodes.<br>
    </li>
  </ul>
</ul>
<blockquote>
  <ul>
    <li>"Wire" uses an event-based implementation based on sockets, and
uses the non-blocking NIO support in Java 1.4. It uses UDP as transport
by default, switching dynamically to TCP for large messages or in the
event that a stream of traffic is sent to a given node. The wire
protocol is till in beta testing, in part because the implementations of
the Java NIO do not yet work properly and efficiently in several Java
VMs on some platforms (for instance, Sun's JDK 1.4.1 RC1 and earlier on
Windows platforms).
<br><br>
Support for simulated killing of nodes is for testing purposes only.
There is a potential to lose any messages that are queued to be sent
when you simulate killing a node. Any such dropped messages will print
the error:<br><br> Potentially lost the message: [message.toString()]<br><br>There
is a known issue in the BSD (FreeBSD, OS X) implementations of Java NIO
that bubbles up the error: "IOException: Bad file descriptor", whenever
a node simulates being killed. We catch the error and print the message
to the command line. Simulated killing of nodes causes instability in
some JVMs prior to JRE 1.4.2.
<br><br>On Unix systems, Java's socket implementation uses File
Descriptors. In this implementation, the File Descriptors can be used
up if too many nodes are running in a single process. If you require
running more than one node inside a single process, consider increasing
the number of File Descriptors per process (bash: ulimit -n), or
lowering the available sockets per node
(rice.pastry.wire.SocketManager.MAX_OPEN_SOCKETS).
</li>
  </ul>
</blockquote>
<blockquote>Future transport protocols will also be based on an open
standard to ensure interoperability among different implementations.</blockquote>
<ul>
  <li> Security support does not exist in this release. Therefore,
the&nbsp; software should only be run in trusted environments. Future
releases will include security.</li>
</ul>
<blockquote>(Background: To start a Pastry node, the IP address (and
port number, unless the default port is used) of a "bootstrap" or
"contact" node  must be provided. If no such node is provided, and no
other Pastry node runs  on the local machine, then FreePastry creates a
new overlay network  with itself as the only node. Any node that is
already part of the Pastry  node can serve as the bootstrap node.)</blockquote>
<ul>
  <li>The Scribe implementation included in this release does not yet
support the tree optimization techniques describe in Sections IV, E-F of
the <a href="http://www.cs.rice.edu/%7Edruschel/publications/Scribe-jsac.pdf">
Scribe paper</a>.<br>
  </li>
</ul>
<p> &nbsp; <br>
&nbsp; <br>
&nbsp; </p>
<h3> Installation</h3>
To use the binary distribution, download the pastry jar file and set
the Java classpath to include the path of the jar file. This can be done
using the "-cp" command line argument, or by setting the CLASSPATH
variable in  your shell environment.
<p>To compile the source distribution, you will need to have GNU make
installed (available from <a href="ftp://ftp.gnu.org/pub/gnu/make">ftp://ftp.gnu.org/pub/gnu/make</a>
, or as part of <a href="http://www.cygwin.com/">cygwin</a> ) on your
system. Expand the archive (FreePastry-1.3.tgz or FreePastry-1.3.zip)
into a directory. Set the environment variables mentioned in setpath.csh
to values appropriate for your system. Execute "make" in the top level
directory (you may have to run "make" twice the first time), then change
to the "classes" directory to run FreePastry.&nbsp; </p>
<p>You may have to provide a Java security policy file with sufficient
permissions to allow FreePastry to contact other nodes. The simplest way
to do this is to install a ".java.policy" file with the following
content into your home directory: </p>
<p>grant { <br>
&nbsp;&nbsp;&nbsp; permission java.security.AllPermission; <br>
}; </p>
<hr>
<h3> Running FreePastry</h3>
1. To run a HelloWorld example:
<pre><b>
     java [-cp pastry.jar] rice.pastry.testing.DistHelloWorld
          [-msgs m] [-nodes n] [-port p] [-bootstrap bshost[:bsport]] [-protocol [socket]]
          [-verbose|-silent|-verbosity v] [-help]

        Without -bootstrap bshost[:bsport], only localhost:p is used for bootstrap.
        Default verbosity is 5, -verbose is 10, and -silent is -1 (error msgs only).

        (replace "pastry.jar" by "FreePastry-&lt;version&gt;.jar", of course)
</b></pre>
<br>
&nbsp;&nbsp;&nbsp; Some interesting configurations:
<pre><b>
  a. java rice.pastry.testing.DistHelloWorld

        Starts a standalone Pastry network, and sends two messages
        essentially to itself. Waits for anyone to connect to it,
        so terminate with ^C.

  b. java rice.pastry.testing.DistHelloWorld -nodes 2

        One node starts a Pastry network, and sends two messages to
        random destination addresses. At some point another node
        joins in, synchronizes their leaf sets and route sets, and
        sends two messages to random destinations. These may be
        delivered to either node with equal probability. Note how
        the sender node gets an "enroute" upcall from Pastry before
        forwarding the message.

  c. java rice.pastry.testing.DistHelloWorld -nodes 2 -verbose

        Also prints some interesting transport-level messages.

  d. pokey$ java rice.pastry.testing.DistHelloWorld
     gamma$ java rice.pastry.testing.DistHelloWorld -bootstrap pokey

        Two machines coordinate to form a Pastry network.

  e. pokey$ java rice.pastry.testing.DistHelloWorld
     gamma$ java rice.pastry.testing.DistHelloWorld -bootstrap pokey

        wait a few seconds, and interrupt with &lt;ctrl-C&gt;

     gamma$ java rice.pastry.testing.DistHelloWorld -bootstrap pokey

        The second client restarts with a new NodeID, and joins the
        Pastry network. One of them sends messages to the now-dead
        node, finds it down, and <em>may or may not</em> remove it<br>        from the leaf sets. (repeat a few times to observe both<br>        possibilities, i.e., leaf sets of size 3 or 5). If the<br>        latter, then leaf set maintenance kicks in within a minute<br>        on one of the nodes, and removes the stale entries.<br>        <br>  f. pokey$ java rice.pastry.testing.DistHelloWorld<br>     gamma$ java rice.pastry.testing.DistHelloWorld -bootstrap pokey -nodes 2<br>     <br>        The client on gamma instantiates two virtual nodes, which<br>        are independent in identity and functionality. Note how the <br>        second virtual node bootstraps from the first (rather than <br>        from pokey). Try starting say 10 or 30 virtual nodes, killing <br>        with a &lt;ctrl-C&gt;, starting another bunch, etc.<br></b></pre>
<br>
2. To run the same HelloWorld application on an emulated network:
<pre><b>
     java [-cp pastry.jar] rice.pastry.testing.HelloWorld [-msgs m] [-nodes n] [-verbose|-silent|-verbosity v] [-simultaneous_joins] [-simultaneous_msgs] [-help]
</b></pre>
<br>
&nbsp;&nbsp;&nbsp; Some interesting configurations:
<pre><b>
  a. java rice.pastry.testing.HelloWorld

        Creates three nodes, and sends total three messages from
        randomly chosen nodes to random destinations addresses
        (which are delivered to the node with the numerically
        closest address).

  b. java rice.pastry.testing.HelloWorld -simultaneous_joins -simultaneous_msgs

        Join all three nodes at once, then issue three messages,
        then go about delivering them.
</b></pre>
<br>
3. To run a regression test that constructs 500 nodes connected by an
emulated network:
<pre><b>
     java [-cp pastry.jar] rice.pastry.testing.DirectPastryRegrTest
</b></pre>
<br>
4. To run a simple performance test based on an emulated network with
successively larger numbers of nodes:
<pre><b>
     java [-cp pastry.jar] rice.pastry.testing.DirectPastryPingTest
</b></pre>
<p> </p>
<h3> Writing applications on top of FreePastry</h3>
Applications that wish to use the native Pastry API must extend the
class rice.pastry.client.PastryAppl. This class implements the Pastry
API. Each application  consists minimally of an application class that
extends rice.pastry.client.PastryAppl, and a driver class that
implements main(), creates and initializes one of  more nodes, etc.
Example applications and drivers can be found in rice.pastry.testing;
the Hello World suite (HelloWorldApp.java,  HelloWorld.java,
DistHelloWorld.java) may be a good starting point.<br>
<br>
Another sample Pastry application is rice.scribe.<br>
<br>
Application writers are stringly encouraged to base newly written
applications on the new common API. Such applications should import the
package rice.p2p.commonapi.<br>
<br>
<hr>
<h3> Running Scribe</h3>
1. To run a simple distributed test:
<pre><b>
     java [-cp pastry.jar] rice.p2p.scribe.testing.ScribeRegrTest [-nodes n] [-port p] [-bootstrap bshost[:bsport]] [-protocol (direct|wire|rmi)] [-help]

        Ports p and bsport refer to contact port numbers (default = 5009).
        Without -bootstrap bshost[:bsport], only localhost:p is used for bootstrap.
        (replace "pastry.jar" by "FreePastry-&lt;version&gt;.jar", of course)
</b></pre>
<br>
<hr>
<h3> Running PAST</h3>
1. To run a simple distributed test: <br>
<pre><b>
     java [-cp pastry.jar] rice.p2p.past.testing.PastRegrTest [-nodes n] [-protocol (direct|wire|rmi)]<br>
</b></pre>
This creates a network of <tt>n</tt> nodes (10 by default), and then
runs the Past regression test over these nodes.
<br>
<hr>
<a name="SplitStream"><h3> Running SplitStream</h3></a>
The FreePastry implementation of SplitStream implements the system
described in the SOSP '03 paper.
<p>
SplitStream.java class provides an interface that can be used by
applications to create SplitStream instances. Each SplitStream forest
is represented by a channel object (Channel.java), where a channel
object encapsulates multiple stripe trees. Each stripe tree for a
SplitStream forest is represented by a class (Stripe.java), which
handles the data reception and subscription failures.
</p><p>
Applications can configure the maximum capacity each channel can
accomodate in terms of number of children it is willing to accept. Applications can control total
outgoing capacity they are willing to provide by changing the value in ScribeSplitStreamPolicy.java.
</p><p>

1. To run a simple distributed test: <br>
</p><pre><b>
     java [-cp pastry.jar] rice.p2p.splitstream.testing.SplitStreamRegrTest [-nodes n] [-protocol (direct|wire|rmi)]<br>
</b></pre>
This creates a network of <tt>n</tt> nodes (10 by default), and then
runs the SplitStream regression test over these nodes.
</body></html>