Modelnet Setup at Rice  
----------------------


Rice cluster:
------------
The machines ( 12 in number) are dual CPU, 4 GB RAM. Out of these some will be running as edge nodes in Modelnet ( runnin Linux) and a few will be running as Modelnet cores (running FREEBSD-4.5-STABLE). 
Each Modelnet Virtual nodes (VNs) running on the edge nodes is assumed to run one Pastry-Java-JVM, which in turn can run multiple Pastry-VNs. Note however that without modifying Pastry, Modelnet cannot emulate latencies between the different Pastry-VNs. Thus different Pastry-VNs will be assumed to be situated in the same LAN. Hence to sacrifice minimum emulation granularity, we should run as fewer Pastry-VNs per JVM as possible. 


Goal 
----

Emulate a approx 5,000 node overlay network



Pastry Application:
------------------

 Using a sample machine (2GB, 2.0 GHz) , I monitored the resources of a simple Pastry testing application which sends approx 10 pkts/sec to random keys and receives the corresponding acks from the overlay roots to be an approx estimate of the CPU load we might expect from different applications on FreePastry. The memory requirements is application specific. ( Monitoring a Scribe like application I found that the memory requirements is only an additional 1 MB per Pastry Node, so I expect the memory requirments of different applications to be roughly in this range). I ran an overlay network of size 250, with 50 Pastry-JVMS and with 5 Pastry-VN per JVM on this machine.




System Bottlenecks at the Modelnet Edge node
-------------------------------------------


 I found that the CPU utilization per Pastry-JVM increases almost linearly with the number of Pastry VNs, implying that the overhead is mostly in the packet processing logic. This was also observed when I increased the packet rate. With 5 Pastry-VNs per JVM, the marginal CPU utilization of a JVM is approx 2 %, i.e 0.4 % per Pastrynode. Thus on the dual CPU machine, we can run atmost 100 Pastry-JVMs/500 Pastry-VNs. 

 With regard to memory, each Pastry-JVM with 5 Pastry-VNs uses around 25 MB memory plus an additional 6.5 MB of shared memory (due to shared Java libraries etc). The marginal cost per Pastry-JVM is around 20 MB and there is an additional marginal cost of 1 MB per Pastry-VN. So on a 4 GB machine, we can run 4 GB/25 i.e 160 Pastry-JVMS/800 Pastry-VNS. Assuming an additional application specific PAST/Scribe memeory requirements of say 3 MB per Pastry node instead of the baseline 1 MB, these values could be approx 4 GB/(20 + 5*3)= 115 Pastry-JVMs/570 Pastry-VNs.


 Thus we see that on an edge node, the CPU bottleneck and the memory bottlenck is well matched with the 5 Pastry-VNs/Pastry-JVM configuration and additionally assuming 5 nodes/LAN in a 10000 node overlay might be acceptable. Thus, we can have 100 Pastry-JVM/500 Pastry-VNs per Modelnet edge node.    



Thus the target overlay size achievable with say 11 edge nodes ( reserving atleast 1  machine for the core) is 5500 node overlay without considering the Modelnet core bottlenecks.



System Bottlecks at the Modelnet Core node
-------------------------------------------

At the modelnet core, the key system bottlenecks that could be affected are : 


a) Incoming bandwidth per core - With 10 pkts per sec, the bandwidth/pastry node is approx 20 Kbps (assuming 250 bytes packet size with custom serialization of Pastry messages that contribute to majority of traffic). Thus wrt bandwidth, a single core can handle 1 Gbps/20 Kbps ~ 50,000 Pastry nodes. Thus aggregate bandwidth is not a bottleneck even when using a single core. 



b) Number of pkts/sec that the core machine hardware can process -

 Assuming that the core machines can process approx 120,000 pkts/sec which is true on most machines today. Thus with 10 pkts/sec per Pastry VN, each core can handle atmost 12,000 Pastry-VNs. Thus with the target size of 5500 Pastry overlay we can achieve with edge node resources, we will not touch this limit either. It is important to remember that with cross-core traffic, some of the fraction of the 120,000 pkts will then be devoted to handling cross core traffic. As we will see below, it seems that a single core can suffice for our target overlay.  


c) CPU requirements at the core

 The CPU requirements at the Modelnet core depends on the number of hops emulated per end-to-end flow. The best configuration with this regard is the end-to-end distillation configuration emulating a single hop per flow. Asuming that todays Internet core is well provisioned and given the type of overlay experiments we perform where latency is the key issue and not the resource contention at the core, this end-to-end distillation seems fine. Another benefit os using the end-to-end distillation phase is that we can use real Internet measurememts as collected in the King matrix from the Vivaldi project or the Kong matrix in Eugene's Latency Generator project. With a single-hop emulation per flow, the Modelnet paper claims that a single core can emulate 120,000 pkts/sec.    



d) Memory requirements at the core

  The packet buffering delay in the Modelnet core is not an issue as claimed in the Modelnet paper since it is around 1 Gb/s * maximum delay of 400 ms, which is around 400 MB. The main memory bottleneck at the core seems to the number of pipes resulting from the Distillation pahse of the topology. Assuming an end-to-end distialltion, the number of pipes is O(n^2) with n being the number of networks we are emulating. Given a 5,500 node overlay with 5 Pastry-VNS per JVM, we are emulating approx 1000 networks resulting in 1000,000 pipes. The Modelnet paper claims to have emulated 100,000 pipes with around 1 GB memory at the core. Emulating 1000,000 pipe means a maximum memory requirement of 4 KB/pipe. The paper does not mention anything about the marginal memory requirement/pipe, so as of know I do not know whether we are hitting memory bottleck at the core. 


 If we are, one option is to alleviate this memory bottleck is by having lesser networks, say 500 networks with 10 Pastry-VNS per JVM. This would result in 250,000 pipes. With 4 GB of memory and given the numbers tested by the Modelnet authors this seems to be a reasonable setting. Increasing the number of Pastry-VNs per JVM at the edge nodes will leave the same CPU bottleneck at the edge node with 500 Pastry-VNs in 50 Pastry-JVMS. But now will will also ease out the memory bottleneck allowing a marginal cost of approx 6 MB per Pastry node since (20 MB of base JVM cost  + 6* 10 Pastry-VNS) * 50 Pastry-JVMS = 4 GB memory.

   Additionally, looking at the bottelecks at the core, downgrading to a lower-end-machine does not make sense because at the core the memory is the bottleck in the end-to-end emulation type, and additionally the CPU could also become the bottleck if we emulate topologies which have more hops per flow (i.e topologies not in the end-to-end distillation). Thus core should have high memeories and having dual CPU's is beneficial. 


Summary
-------

The summary of the above analysis is that we can achieve a 5500 node overlay with 11 edge nodes and a single core using the Rice cluster and using a configuration of 10 Pastry-VNs per Pastry JVM. We should install FreeBSD-4.5-STABLE on one of the machines to make it the Modelnet core.

