<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head>
</head>
<body bgcolor="white">

This is an implementation of (@see rice.pastry.dist.DistPastryNode DistPastryNode) 
for IP.  

see UML diagram

High level design considerations: <br>
<T3>Hybrid TCP/UDP design:</T3>
TCP has several advantages over UDP for bandwidth, interoperability and 
simplicity.  However, at the JAVA level, much of the low level aspects are hidden
from the developer for simplicity.  However, it is difficult to determine if delays 
are the result of constrained bandwidth, or if the node has simply dropped
off the network.  Furthermore, TCP connections may be maintained (at a lower level) for an app that has 
stalled, thus never causing a socket to terminate, or process any data level communications.
Doing 100% UDP communications at the Java level can cause a host of problems.  The one
that seems most difficult to overcome is the timing required to give good bandwidth
if it is only managed at the Java level.  (As opposed to TCP which is managed at a much
lower level.)  This solution implements TCP for <i>all</i> communications except liveness
checks (like ping).
<p>To keep application traffic from interfering with control traffic, it is necessary 
to limit the size of app level messages utilizing the overlay's TCP pipe.  Otherwise a very
large message could eliminate the library's ability to deliver timely overlay traffic responses.
However we feel it is important to support app traffic of any size, so the obvious 
solutions are: <br>
1) Chunking.  <br>
2) Use a second "Data" TCP connection. <br>
Chunking adds additional complexity, and when sending large messages, 
it is likely the app will already need to do it's own chunking, for example to use
blocking disk IO.  Double chunking will be expensive for memory and CPU, so we decided
against this approach.<br>
The data connection has no limitations imposed in rice.pastry.socket, except a maximum 
number of messages pending to be written.  (@see SocketCollectionManager.blargh)
<br><br>
Single threaded design:
rice.pastry.socket was an attempt to reduce the complexity of rice.pastry.wire.  While we
have simplified many aspects of wire, one of the most significant changes is that we do not 
do work on any thread except the Selector thread.  This eliminates synchronization overhead
that was rarely used, but required in wire.  It also makes the code much simpler to 
modify and maintain.  We are now using profilers to keep the performance high even though
we are single threaded now.  Realize that we expect user code to complete quickly on a 
call to Application.receiveMessage() because this is the only thread that the rice.pastry.socket 
has, and it is also used to read/write to the TCP buffers.
<br><br>
Library Level acknowledgements:
The control sockt uses acknowledgements for all traffic.  The primary reason to do this is to ensure
high performance routing.  If an ack is not received in the expected amount of time,
the message will be rerouted if appropriate (such as if the node in question is not the final destination
for the packet), and a (UDP) liveness check will begin if appropriate.  See blah paper.  We use an adaptive
algorithm nearly identical to TCPs to estimate the expected time of a message acknowledgement and ping
response times.
<br><br>
FileDescriptor management:
In most UNIX systems there is a maximum FD limit for each process.  If not properly managed, a 
pastry node could open a lot of Sockets to remote nodes.  For this reason we control the number of
sockets allowed for each node.  (@see SocketPoolManager.MAX_OPEN_SOCKETS).

Where to start:
SocketPastryNode implements DistPastryNode, so this represents the interface to pastry. 
SocketCollectionManager holds the pool of ConnectionManagers in a 1 to 1 relationship with
the SocketPastryNodes.
ConnectionManager manages all the state specific to a remote node.  This includes
liveness state and TCP sockets.
  ConnectionManager utilizes PingManger to do the actual UDP communication.  There is only one of these
  for an entire PastryNode, becasue we can share the UDP server for communication with all other nodes.
  ConnectionManager utilizes SocketManager to manage the TCP communication.  There are up to 2 of these 
  connections to each remote node.  One for control/routing, the other for data.
SocketManager manages bidirectional TCP communication to a single node, of a single type (control/routing, or data).
SocketPoolManager makes sure we enforce the SocketPoolManager.MAX_OPEN_SOCKETS limitation.
The rest of the classes serve one or more of these classes.


<h2>Package Specification</h2>

##### FILL IN ANY SPECS NEEDED BY JAVA COMPATIBILITY KIT #####
<ul>
  <li><a href="">##### REFER TO ANY FRAMEMAKER SPECIFICATION HERE #####</a>
</ul>

<h2>Related Documentation</h2>

For overviews, tutorials, examples, guides, and tool documentation, please see:
<ul>
  <li><a href="">##### REFER TO NON-SPEC DOCUMENTATION HERE #####</a>
</ul>

<!-- Put @see and @since tags down here. -->

</body>
</html>
