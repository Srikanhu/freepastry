<html><head>
  <title>FreePastry Tutorial</title>
  <link rel="stylesheet" href="tutorial.css" />
</head>
<body>

<div class="content">
<div class="frontmatter">

<h1>The FreePastry Tutorial.</h1>

<div class="abstract">This tutorial is designed to get you cooking quickly with the FreePastry
API and software toolkit.</div>

<h4>Version @tutorial_version@; @tutorial_date@.  For <a
href="http://freepastry.org/">FreePastry</a> version @freepastry_version@.  Maintained by @maintainer@.</h4>

</div>

<a name="layer"><h1>Transport Layers</h1></a>
<h2>Modify low level details of FreePastry's network stack.</h2>

<div class="nav">
  <span class="nav-left"><a href="tut_forward.html#forward">Previous (Forwarding)</a></span> 
  <span class="nav-center"><a href="index.html">Contents</a></span> 
  <span class="nav-right"><a href="tut_cancellable_msg.html">Next (Cancellable Messages)</a></span>
</div><br/><hr/>

<p/>This tutorial will show you how to use the new TransportLayer interface in the package org.mpisws.p2p.transport.  It will also show you how to integrate your TransportLayer to the SocketPastryNodeFactory network stack.

<p/><b>Warning:</b> This tutorial is more difficult than the previous tutorials and is intended for developers who wish to make low-level changes to the FreePastry network stack. 

<p/>We will start by stating some of the goals of the the <i>Layered Transport Layer</i>.  

<p/>Versions of FreePastry before 2.1 had a unified transport layer.  When features at this level needed to be added or modified, it was very complicated to get all of the parts to work properly.  The new version rearranges network transport into a stack of layers where each has it's own small task. 

<p/>To give you an idea of what a typical task of a layer, we will describe the layers that are assembled when creating the SocketPastryNodeFactory in FreePastry 2.1, beginning with the lowest layer:

<h3>SocketPastryNodeFactory's Layers:</h3>
<ul>
  <li><b>Wire</b> -- Opens/Accepts Sockets, Sends/Receives Datagrams</li>
  <li><b>MagicNumber</b> -- Throws away sockets/datagrams for other applications such as HTTP (if it doesn't match the application specific magic number)</li>
  <li><b>MultiInetAddressTransportLayer</b> -- Handles multi-homing (ex, when using a NAT a node may have more than 1 address:port, the internal address, and the NAT's external address that is forwarded)</li>
  <li><b>SourceRoute</b> -- sends messages/opens sockets along a source route, this layer manages both the endpoints and the intermediate nodes, note that this layer does <i>not</i> determine the optimal route to an end host, that is done by another layer, the <i>SourceRouteManager</i>.</li>
  <li><b>LowerIdentity</b> -- This layer, in conjunction with the <i>UpperIdenity</i> maintains the "intention" of the sent/received message.  For example, if a node has restarted with a different NodeId this layer drops pings/sockets if they were intended for the previous node at this address.</li>
  <li><b>Liveness</b> -- Pings nodes to determine liveness/proximity, implements 2 new interfaces: <i>LivenessProvider, Pinger</i> </li>
  <li><b>SourceRouteManager</b> -- Chooses the appropriate SourceRoute based on the liveness/proximity of the lower layer, implements another new interface <i>ProximityProvider</i></li>
  <li><b>Priority</b> -- Uses a single TCP socket to send messages.  Can select the order of the messages based on the priority.</li>
  <li><b>UpperIdentity</b> -- (See Lower Identity) This layer keeps track of the intended destination of the message so that the lower layer can properly encode that intention.</li>
  <li><b>CommonAPI</b> -- Serializes/Deserializes messages from a RawMessage to a ByteBuffer.</li>
</ul>

<p/>As you can see, some of these layers depend on lower layers and don't make much sense by themself, ex: <b>SourceRoute/SourceRotueManager</b>, <b>Lower/Upper Identity</b> layers.

<h3>Other interesting layers:</h3>

<ul>
  <li><b>DirectTransportLayer</b> -- This implements the discreet event simulator, and is used by the DirectPastryNodeFactory.</li>
</ul>

<h3>Upcoming layers:</h3>
<ul>
  <li><b>SSL</b> -- Provides Crypto/Authentication (typically goes above the SourceRoute layer to provide end-to-end crypto/auth)</li>
  <li><b>BandwidthLimiting</b> -- Limits the Bandwidth of a node (typically goes between MagicNumber/SourceRoute Layers)</li>
  <li><b>PeerReview</b> -- Provides protocol accountability (typically goes near the top, such as between CommonAPI/Priority layers)</li>
  <li><b>STUN</b> -- would likely replace the Wire Layer and provide NAT hole-punching</li>
</ul>

<p/>Note: The TranportLayer uses a new feature of Java 1.5, generics.  For more informaiton on Generics, see this <a href="http://java.sun.com/j2se/1.5/pdf/generics-tutorial.pdf">this tutorial</a>.

<h3>The TransportLayer interface:</h3>
<pre>
public interface TransportLayer&lt;Identifier, MessageType&gt; extends Destructable {}
</pre>

<p/>Each transport layer operates on an <i>Identifier</i> (<b>InetSocketAddress</b>, <b>SourceRoute</b>, <b>NodeHandle</b> etc), and a <i>MessageType</i> (<b>ByteBuffer</b>, <b>RawMessage</b> etc)

<p/>The most common operations are <i>sending messages</i> and <i>opening sockets</i>:
<pre>
  public MessageRequestHandle&lt;Identifier, MessageType&gt; sendMessage(
    Identifier i, 
    MessageType m, 
    MessageCallback&lt;Identifier, MessageType&gt; deliverAckToMe, 
    Map&lt;String, Integer&gt; options);

  public SocketRequestHandle&lt;Identifier&gt; openSocket(
    Identifier i, 
    SocketCallback&lt;Identifier&gt; deliverSocketToMe, 
    Map&lt;String, Integer&gt; options);
</pre>

<p/>For these methods, you need the <b>Identifier</b> of the remote node, and (for <code>sendMessage()</code>) the <b>Message</b> to be delivered.  Additionally, you may specify some transport-layer specific <b>Options</b> such as <i>Guaranteed</i>/<i>Unguaranteed</i>/<i>Encrypted</i> etc.  We will describe some of these options in a later tutorial.  Finally you provide a <b>Callback</b> (<code>deliverAckToMe</code>/<code>deliverSocketToMe</code>) to deliver notificaiton of success or failure when the operation completes.  These calls are non-blocking and return a <b>RequestHandle</b>.  The RequestHandle is like a receipt or a tracking number.  You can use the RequestHandle to cancel the existing request if it is no longer necessary.  For example if the operaiton takes too long.  The <a href="tut_cancellable_msg.html">next tutorial</a> shows you how to work with a RequestHandle.

<a name="callback"><h3>The TransportLayerCallback interface:</h3></a>
<p/>The <code>TransportLayerCallback</code> provides the inverse operations (the result of a remote node sends a message or opens a socket) and must have the identical <i>Identifier</i>/<i>MessageType</i>:

<pre>
public interface TransportLayerCallback&lt;Identifier, MessageType&gt; {
  public void messageReceived(Identifier i, MessageType m, Map&lt;String, Integer&gt; options) throws IOException;

  public void incomingSocket(P2PSocket&lt;Identifier&gt; s) throws IOException;
}
</pre>

<p/>The P2PSocket is similar to the <a href="tut_app_sockets.html">AppSocket</a>.

<h3>Other calls in the TransportLayer:</h3>

<p/>This method returns the Identifier of the local node for this layer.
<pre>
  public Identifier getLocalIdentifier();
</pre>

<p/>These methods can control flow by rejecting new messags/sockets if the local node is being overwhelmed.   
<pre>
  public void acceptSockets(boolean b);
  
  public void acceptMessages(boolean b);
</pre>
  
<p/>This method sets the <a href="#callback">callback</a>
<pre>
  public void setCallback(TransportLayerCallback&lt;Identifier, MessageType&gt; callback);
</pre>

<p/>This method sets the <code>ErrorHandler</code> which is usd for notification of unexpected behavior.  Ex: The acceptor socket closes, or an unexpected message arrives
<pre>
  public void setErrorHandler(ErrorHandler&lt;Identifier&gt; handler);  
</pre>

<p/>This method cleans up the layer, for example closing down the AcceptorSocket.
<pre>
  public void destroy();
</pre>

<h3>Your first new TransportLayer</h3>

<h4>Overview:</h4>
<ul>
  <li>In this tutorial, we'll create a new tranport layer that caps the peak outgoing bandwidth.  We will use a bucket sysetem with configurable bandwidth and bucket time limit. For example if we want to limit bandwidth to 10K/second, we can allow 10K for any second, or 1K for 1/10th of second.</li>  

  <li>For simplicity, we won't distinguish between socket and datagram traffic.</li>  

  <li>The obvious place for this layer will be just above the Wire layer, but to provide maximum flexibility, we would like this layer to work with any <i>Identifier</i>.  Thus we will keep this parameter <i>generic</i>.</li>  

  <li>We will have to specify a message type that we can determine the size.  In this case, we'll use the <code>ByteBuffer</code> as our Message type.</li>  

  <li>To insert our new layer between 2 existing layers, we also need to implement a <code>TransportLayerCallback</code> of the same types so we can insert ourself between two existing layers.</li>  
</ul>

<h3>Download the tutorial files: 
<a href="./src/transportlayer/BandwidthLimitingTransportLayer.java">BandwidthLimitingTransportLayer.java</a>
<a href="./src/transportlayer/NotEnoughBandwidthException.java">NotEnoughBandwidthException.java</a>
<a href="./src/transportlayer/DistTutorial.java">DistTutorial.java</a>
<a href="./src/transportlayer/MyApp.java">MyApp.java</a>,
<a href="./src/transportlayer/MyMsg.java">MyMsg.java</a> into a directory called rice/tutorial/transportlayer/.</h3>



<p/>Here is the definition of our new class.
<pre>
public class BandwidthLimitingTransportLayer&lt;Identifier&gt; implements 
    TransportLayer&lt;Identifier, ByteBuffer&gt;,
    TransportLayerCallback&lt;Identifier, ByteBuffer&gt; {
}
</pre>

<p/>Here is the constructor.  It takes the <code>TransportLayer</code> below this layer, the bucket size, and bucket time length.  We also want access to environment so we can create a logger.
<pre>
  public BandwidthLimitingTransportLayer(
      TransportLayer&lt;Identifier, ByteBuffer&gt; tl, 
      long bucketSize, int bucketTimelimit, 
      Environment env) {
    this.environment = env;
    this.tl = tl;
    BUCKET_SIZE = bucketSize;
    BUCKET_TIME_LIMIT = bucketTimelimit;    
    logger = env.getLogManager().getLogger(BandwidthLimitingTransportLayer.class, null);
    tl.setCallback(this);
  }
</pre>
<p/>You can look at the code to see the declaration of these fields.  The last thing we have to do is set ourself as the lower level's callback.  This will cause it to deliver messages/sockets to us.

<p/>This variable is the bucket.
<pre>
  /**
   * When this goes to zero, don't send messages
   */
  protected long bucket;
</pre>

<p/>Now let's create a task to refil the bucket.
<pre>
    environment.getSelectorManager().getTimer().schedule(new TimerTask(){    
      @Override
      public void run() {
        // always synchronize on "this" before modifying the bucket
        synchronized(this) {
          bucket = BUCKET_SIZE;
        }
      }    
    }, 0, BUCKET_TIME_LIMIT);
</pre>
<p/>If the TimerTask is unfamiliar, please review <a href="tut_timertask.html#timer">the timer tutorial</a>.  This interface is slightly different in that it calls <code>run()</code>, rather than sending a <code>MessageToSelf</code>, but it is the same idea. 

<h4>Limit Message Bandwidth</h4>
<p/>Now let's limit the outgoing message bandwidth.  We are going to throw a <code>NotEnoughBandwidthException</code> if there isn't sufficient bandwidth to send a message.  
<p/>There are three things we must do here.  
<ul>
  <li>Subtract from the bucket or throw the exception.</li>
  <li>Return a proper Message receipt so the task can be cancelled.</li>
  <li>Acknowledge the message when the lower transport layer acknowledges it to us.</li>
</ul>

<p/>This shows the code to subtract from the bucket or throw the exception.  For now, we retun null.  All we have to do is call <code>deliverAckToMe.sendFailed()</code> when there isn't enough bandwidth.  Note: The <code>MessageCallback</code> may be null, so we must check that it isn't before calling sendFailed() otherwise we will get a NullPointerException.  Also, so we can detect that this is occuring when we run the code, we will log when the message is dropped.
<pre>
  public MessageRequestHandle&lt;Identifier, ByteBuffer&gt; sendMessage(
      Identifier i, 
      ByteBuffer m, 
      MessageCallback&lt;Identifier, ByteBuffer&gt; deliverAckToMe, 
      Map&lt;String, Integer&gt; options) {

    boolean success = true;
    synchronized(this) {
      if (m.remaining() > bucket) {
        success = false;
      } else {
        bucket-=m.remaining();
      }
    }
    if (!success) {
      if (logger.level <= Logger.FINE) logger.log("Dropping message "+m+" because not enough bandwidth:"+bucket);
      if (deliverAckToMe != null) 
        deliverAckToMe.sendFailed(null, new NotEnoughBandwidthException(bucket, m.remaining()));
      return null;
    }
    tl.sendMessage(i,m,deliverAckToMe,options);
  }  
</pre>

<p/>Now we will add code to return a proper <code>MessageRequestHandle</code>, as well as supply the MessageRequestHandle when the message succeeds or fails.  The release already includes a generic implementation of the MessageRequestHandle: org.mpisws.p2p.transport.util.MessageRequestHandleImpl.  Let's take a look at it:

<p/>The constructor initializes these 3 fields:
<pre>
  Identifier identifier;
  MessageType msg;
  Map&lt;String, Integer&gt; options;
</pre> 

<p/>There are also corresponding getters.  However, we still need to be able to <code>cancel()</code> the operation in the next transport layer.  This requires the 4th field:
<pre>
  Cancellable subCancellable;

  public boolean cancel() {
    if (subCancellable == null) return false;
    return subCancellable.cancel();
  }
</pre>

<p/>The <code>subCancellable</code> is initialized with a call to <code>setSubCancellable()</code>.

<p/>Here is the code that now properly returns a <code>MessageRequestHandle</code>:
<pre>
  public MessageRequestHandle&lt;Identifier, ByteBuffer&gt; sendMessage(Identifier i, ByteBuffer m, 
    MessageCallback&lt;Identifier, ByteBuffer&gt; deliverAckToMe, Map&lt;String, Integer&gt; options) {

    MessageRequestHandleImpl&lt;Identifier, ByteBuffer> returnMe = 
      new MessageRequestHandleImpl&lt;Identifier, ByteBuffer&gt;(i, m, options);
    
    boolean success = true;
    synchronized(this) {
      if (m.remaining() > bucket) {
        success = false;
      } else {
        bucket-=m.remaining();
      }
    }
    if (!success) {
      if (logger.level <= Logger.FINE) logger.log("Dropping message "+m+" because not enough bandwidth:"+bucket);
      if (deliverAckToMe != null) 
        deliverAckToMe.sendFailed(returnMe, new NotEnoughBandwidthException(bucket, m.remaining()));
      return returnMe;
    }
    
    returnMe.setSubCancellable(tl.sendMessage(i,m,deliverAckToMe,options));
    return returnMe;
  }  
</pre>

<p/>Note how we call <code>returnMe.setSubCancellable()</code> with the call to the lower transportLayer.

<p/>There is one more problem in the code.  Because we simply pass through the deliverAckToMe field, when <code>deliverAckToMe.ack()</code> or <code>deliverAckToMe.sendFailed()</code> is called, it will have the wrong MessageRequestHandle.  Thus, we need to create our own MessageRequestHandle which wraps <code>deliverAckToMe</code>.  
<p/>First, we need to do is declare <code>deliverAckToMe</code> and <code>returnMe</code> <i>final</i>.  
<p/>Second, we will create an anonymous inner class of the <code>MessageCallback</code>.

<pre>
  public MessageRequestHandle&lt;Identifier, ByteBuffer&gt; sendMessage(Identifier i, ByteBuffer m, 
      final MessageCallback&lt;Identifier, ByteBuffer&gt; deliverAckToMe, Map&lt;String, Integer&gt; options) {

    final MessageRequestHandleImpl&lt;Identifier, ByteBuffer&gt; returnMe = 
      new MessageRequestHandleImpl&lt;Identifier, ByteBuffer&gt;(i, m, options);
    
       ...

    returnMe.setSubCancellable(tl.sendMessage(i,m,new MessageCallback&lt;Identifier, ByteBuffer&gt;() {
      public void ack(MessageRequestHandle&lt;Identifier, ByteBuffer&gt; msg) {
        if (deliverAckToMe != null) deliverAckToMe.ack(returnMe);
      }

      public void sendFailed(MessageRequestHandle&lt;Identifier, ByteBuffer&gt; msg, IOException reason) {
        if (deliverAckToMe != null) deliverAckToMe.sendFailed(returnMe, reason);
      }    
    },options));
    return returnMe;
  }  
</pre>

<p/>Our <code>MessageCallback</code> simply calls <b>deliverAckToMe</b>'s <code>ack()/sendFailed()</code> methods with <b>returnMe</b>.

<p/>Here is the full code for the method:
<pre>
  public MessageRequestHandle&lt;Identifier, ByteBuffer&gt; sendMessage(Identifier i, ByteBuffer m, 
      final MessageCallback&lt;Identifier, ByteBuffer&gt; deliverAckToMe, Map&lt;String, Integer&gt; options) {

    final MessageRequestHandleImpl&lt;Identifier, ByteBuffer&gt; returnMe = 
      new MessageRequestHandleImpl&lt;Identifier, ByteBuffer&gt;(i, m, options);
    
    boolean success = true;
    synchronized(this) {
      if (m.remaining() > bucket) {
        success = false;
      } else {
        bucket-=m.remaining();
      }
    }
    if (!success) {
      if (logger.level <= Logger.FINE) logger.log("Dropping message "+m+" because not enough bandwidth:"+bucket);
      if (deliverAckToMe != null) deliverAckToMe.sendFailed(returnMe, new NotEnoughBandwidthException(bucket, m.remaining()));
      return returnMe;
    }
    
    returnMe.setSubCancellable(tl.sendMessage(i,m,new MessageCallback&lt;Identifier, ByteBuffer&gt;() {
      public void ack(MessageRequestHandle&lt;Identifier, ByteBuffer&gt; msg) {
        if (deliverAckToMe != null) deliverAckToMe.ack(returnMe);
      }

      public void sendFailed(MessageRequestHandle&lt;Identifier, ByteBuffer&gt; msg, IOException reason) {
        if (deliverAckToMe != null) deliverAckToMe.sendFailed(returnMe, reason);
      }    
    },options));
    return returnMe;
  }  
</pre>

<p/>This may seem a bit overwhelming right now, but this code provides a lot of flexibility for the transport layer while still keeping the calls simple.

<h4>Limit Socket Bandwidth</h4>
<p/>The last major step is making the Sockets also respect the bandwith limitations.  Rather than throwing an exception when we exceed the bandwidth, we just need to throttle the traffic, by only sending what we are allowed.  To do this, we will create a <code>P2PSocket</code> that decrements the bucket on each write.  Like the <code>MessageRequestHandleImpl</code>, we already have an implementation of a <code>P2PSocket</code> that wraps another.  It is called the org.mpisws.p2p.transport.util.SocketWrapperSocket.  

<p/>The generic parameters of the <code>SocketWrapperSocket</code> are the 2 kinds of Identifiers that it Adapts.  Since we are importing and exporting the same Identifier, we declare our Socket like this:

<pre>
  class BandwidthLimitingSocket extends SocketWrapperSocket&lt;Identifier, Identifier&gt; {
  }
</pre>

<p/>Now we need to set up the constructor.  We will provide it the wrapped socket's identifier and options.   Also, we must pass it our <code>logger</code>.
<pre>
    public BandwidthLimitingSocket(P2PSocket&lt;Identifier&gt; socket) {
      super(socket.getIdentifier(), socket, 
            BandwidthLimitingTransportLayer.this.logger, 
            socket.getOptions());
    }
</pre>


<p/>Now we need to override these two methods:
<pre>
    @Override
    public long write(ByteBuffer srcs) throws IOException {}

    @Override
    public long write(ByteBuffer[] srcs, int offset, int length) throws IOException {}
</pre>

<p/>Let's start with the first method.
<p/>Here is the easy case, where we accept the <code>write()</code>, or log a message:
<pre>
      if (srcs.remaining() <= bucket) {
        long ret = super.write(srcs);
        if (ret >= 0) {
          // EOF is usually -1
          synchronized(this) {
            bucket -= ret;
          }
        }
        return ret;
      }

      if (logger.level <= Logger.FINE) logger.log("Limiting "+socket+" to "+bucket+" bytes.");
</pre>

<p/>The rest is complicated, because it is important to leave the incoming ByteBuffer's position in the proper place. 

<p/>We create a variable <code>ByteBuffer temp</code> with the amount of space left in the buffer:
<pre>
      // we're trying to write more than we can, we need to create a new ByteBuffer
      // we have to be careful about the bytebuffer calling into us to properly 
      // set the position when we are done, let's record the original position
      int originalPosition = srcs.position();
      ByteBuffer temp = ByteBuffer.wrap(srcs.array(), originalPosition, bucket);
</pre>

<p/>Now we try to write the data by calling super.  This method may throw an IOException or return EOF.  Fortunately, the <code>srcs</code> buffer is in its original position, so we don't need to do anything but return/throw exception:
<pre>
      // try to write our temp buffer
      long ret = super.write(temp);
      
      if (ret < 0) {
        // there was a problem,
        // reset the position, return
        return ret;
      }
</pre>

<p/>If we made it here there were no problems.  Allocate the bandwidth and update the position on the <code>srcs</code> ByteBuffer:
<pre>
      // allocate the bandwidth
      synchronized(this) {
        bucket -= ret;
      }
      
      // the lower layer couldn't write as much as we wanted to
      // we need to properly set the position
      srcs.position(originalPosition+(int)ret);
      return ret;
</pre>

<p/>The code for the other <code>write()</code> method is similar, but setting the position is more complicated.  The first part is similar to before, add up how much to send, and call super if we aren't overflowing.
<pre>
      // calculate how much they are trying to write:
      int toWrite = 0;
      for (int i = offset; i < offset+length; i++) {
        toWrite += srcs[i].remaining();
      }
      
      int tempBucket = bucket; // so we don't get confused by synchronization
                  
      if (toWrite <= tempBucket) {
        long ret = super.write(srcs, offset, length);
        if (ret >= 0) {
          // EOF is usually -1
          synchronized(this) {
            bucket -= ret;
          }
        }
        return ret;
      }

      if (logger.level <= Logger.FINE) logger.log("Limiting "+socket+" to "+bucket+" bytes.");
</pre>

<p/>Note: <i>We use the variable tempBucket so we don't get confused if the bucket is refilled asynchronously.</i>

<p/>The strategy now is to make a copy of the <code>srcs</code> array.  This code finds the ByteBuffer that causes the overflow.  We will replace that item with a temporary buffer as in the above example.
<pre>
      // we're trying to write more than we can, we need to create a new ByteBuffer
      // in the overflowing position, and set the length properly      
      // we have to be careful about the bytebuffer calling into us to properly 
      // set the position when we are done
      ByteBuffer[] temp = new ByteBuffer[srcs.length];
      System.arraycopy(srcs, 0, temp, 0, srcs.length);
      int myLength = length; // we'll pass this to the call that we want
      int myIndex = 0;
      toWrite = 0; // reset this one
      for (int i = offset; i < offset+length; i++) {
        int next = srcs[i].remaining();
        if (next+toWrite > tempBucket) {
          //we have the problem at this slot
          
          // set the myLength
          myLength = i-offset+1;
          myIndex = i;
          
          // replace it with a temporary byteBuffer
          srcs[i] = ByteBuffer.wrap(srcs[i].array(), srcs[i].position(), tempBucket-toWrite);
          break;
        }
        toWrite+=next;
      }
</pre>

<p/>This code looks like the previous example, but we may need to advance the position of the buffer we replaced.  
<pre>
      // try to write our temp buffer
      long ret = super.write(temp, offset, myLength);
      
      if (ret < 0) {
        // there was a problem
        return ret;
      }
      
      // allocate the bandwidth
      synchronized(this) {
        bucket -= ret;
      }
      
      // we need to properly set the position on the buffer we replaced
      // the idea here is that we are advancing the srcs[i].position() with the
      // amount that was written in temp[i].position()
      srcs[myIndex].position(srcs[myIndex].position()+temp[myIndex].position());
      return ret;
</pre>

<p/>We're not done yet.  Because we are simply passing through the request to write, this will cause an infinite loop when we run out of bandwidth.  It goes something like this.

<ul>
  <li><b>Client:</b> socket.register() // request to write (passed through to the lower layer).</li>
  <li><b>Lower layer:</b> receiver.receiveSelectResult() // granted request to write</li>
  <li><b>Client:</b> socket.write()</li>
  <li><b>BandwidthLimitingLayer:</b> limiting bandwidth to 0 bytes, write returns 0</li>
  <li><i>repeat</i> -- The user code didn't make any progress, so obviously it will register again.</li>
</ul>

<p/>To remedy this situation, we need to do two things:
<ul>
  <li>Intercept the call to <code>socket.register()</code></li>
  <li>Have make our refill task notify the sockets so they can register these sockets later.</li>
</ul> 

<p/>Let's make a member variable in <code>BandwidthLimitingSocket</code> to store the requesting receiver:
<pre>
    /**
     * Store the write requestor.
     */
    P2PSocketReceiver&lt;Identifier&gt; storedReceiver;
</pre>


<p/>Here is the code to intercept <code>socket.register()</code> in <code>BandwidthLimitingSocket</code>.  If we are out of bandwidth and the user wants to write, then we cache the receiver in the <code>storedReceiver</code> variable.
<pre>
    @Override
    public void register(boolean wantToRead, boolean wantToWrite, 
        P2PSocketReceiver&lt;Identifier&gt; receiver) {

      // this variable is what we will pass to super.register()
      boolean myWantToWrite = wantToWrite;
      
      // if the user wants to write, and the bucket is empty, set our temp variable to false
      if (wantToWrite == true && bucket == 0) {
        myWantToWrite = false;
        storedReceiver = receiver;
      }

      // only call super.register() if we have something to do
      if (wantToRead || myWantToWrite) super.register(wantToRead, myWantToWrite, receiver);
    }
</pre>

<p/>Now, our refill task needs to notify all sockets so they can register to write if they have a <code>storedReceiver</code>.

<p/>We need to keep track of all of our <code>BandwidthLimitingSocket</code>s in a Collection called sockets.  Whenever we create a <code>BandwidthLimitingSocket</code> we add it to sockets, and whenever we <code>shutdownOutput()</code> or <code>close()</code> the socket, we remove it.

<pre>
  /**
   * Keep track of all of the BandwidthLimitingSocket
   */
  Collection&lt;BandwidthLimitingSocket&gt; sockets = new ArrayList&lt;BandwidthLimitingSocket&gt;();
  
  class BandwidthLimitingSocket extends SocketWrapperSocket&lt;Identifier, Identifier&gt; {
    public BandwidthLimitingSocket(P2PSocket&lt;Identifier&gt; socket) {

      super(socket.getIdentifier(), socket, 
            BandwidthLimitingTransportLayer.this.logger, socket.getOptions());

      synchronized(BandwidthLimitingTransportLayer.this) {
        sockets.add(this);
      }
    }

    public void close() {
      super.close();
      synchronized(BandwidthLimitingTransportLayer.this) {
        sockets.remove(this);      
      }
    }
    
    public void shutdownOutput() {
      super.shutdownOutput();
      synchronized(BandwidthLimitingTransportLayer.this) {
        sockets.remove(this);
      }
    }
</pre>

<p/>We also need a method for the refill task to call.

<pre>
    /**
     * Register and clear the storedReceiver
     */
    public void notifyBandwidthRefilled() {
      if (storedReceiver != null) {
        P2PSocketReceiver&lt;Identifier&gt; temp = storedReceiver;
        storedReceiver = null;
        super.register(false, true, temp);
      }
    }
</pre>

<p/>Now modify the refill task to call <code>notifyBandwidthRefilled()</code>.  <i>This code was in the constructor for BandwidthLimitingTransportLayer.</i>
<pre>
          for (BandwidthLimitingSocket s : sockets) {
            s.notifyBandwidthRefilled();
          }
</pre>

<p/>Phew, that was lot of work.  Now that we have our <code>BandwidthLimitingSocket</code>, we need to use it.  
<p/>There are two ways to get a socket.  
<ul>
  <li>When the upper layer opens a socket.</li>
  <li>When the lower layer accepts a socket.</li>
</ul>

<h3>openSocket():</h3>
<p/>Here is the code for <code>openSocket()</code>.  We don't get the socket right away.  We have to wait until it has completed opening.  This is similar to a <a href="tut_continuations.html#lesson0a">continuation</a>.  The first thing we have to do is create a <code>SocketRequestHandle</code> for the same reasons as we did in the above code with <code>MessageRequestHandle</code>.
<pre>
    SocketRequestHandleImpl&lt;Identifier&gt; returnMe = new SocketRequestHandleImpl&lt;Identifier&gt;(i,options);
    returnMe.setSubCancellable(tl.openSocket(i, ... , options));  
    return returnMe;
</pre>

<p/>Now, we ask the lower transport layer to open the socket, and then we will wrap it with our <code>BandwidthLimitingSocket</code> which we will return to <b>deliverSocketToMe</b>.  If there is an Exception, we just pass it up to the previous layer.  Note that it deliverSocketToMe must be non-null, because it's not useful to request opening a socket if you don't receive a handle to it.
<pre>
  tl.openSocket(i, new SocketCallback&lt;Identifier&gt;(){
      public void receiveResult(SocketRequestHandle&lt;Identifier&gt; cancellable, P2PSocket&lt;Identifier&gt; sock) {
        deliverSocketToMe.receiveResult(returnMe, new BandwidthLimitingSocket(sock));
      }
    
      public void receiveException(SocketRequestHandle&lt;Identifier&gt; s, IOException ex) {
        deliverSocketToMe.receiveException(returnMe, ex);
      }
    }, options)
</pre>

<h3>incomingSocket():</h3>
<p/>Here is the code for <code>incomingSocket()</code>.  First, we need a callback to deliver the socket to.  This will be set later, but we will implement the setCallback() method in TransportLayer.
<pre>
  TransportLayerCallback&lt;Identifier, ByteBuffer&gt; callback;
  public void setCallback(TransportLayerCallback&lt;Identifier, ByteBuffer&gt; callback) {
    this.callback = callback;
  }
</pre>

<p/>Now it is simple to override <code>incomingSocket()</code>
<pre>
  public void incomingSocket(P2PSocket&lt;Identifier&gt; s) throws IOException {
    callback.incomingSocket(new BandwidthLimitingSocket(s));
  }
</pre>

<p/>The last step is to add all of the rest of the methods in TransportLayer, transportLayerCallback.  These are just going to forward the calls down or up as appropriate:
<pre>
  public void acceptMessages(boolean b) {
    tl.acceptMessages(b);
  }

  public void acceptSockets(boolean b) {
    tl.acceptSockets(b);
  }

  public Identifier getLocalIdentifier() {
    return tl.getLocalIdentifier();
  }

  public void setErrorHandler(ErrorHandler&lt;Identifier&gt; handler) {
    tl.setErrorHandler(handler);
  }

  public void destroy() {
    tl.destroy();
  }

  public void messageReceived(Identifier i, ByteBuffer m, Map&lt;String, Integer&gt; options) throws IOException {
    callback.messageReceived(i, m, options);
  }
</pre>

<h4>Integration with the SocketPastryNodeFactory</h4>
<p/>Where should we put this layer?  We will show two options.

<p/>Because we are at the Java level, we already kon we can't fully account for the TCP overhead of the bandwidth (retransmission etc).  However to get the maximum effect, we should place it just above Wire.  Here, we show how to do this by extending SocketPastryNodeFactory.  

<p/>The SocketPastryNodeFactory in FreePastry version 2.1 is much more extensible than before.  There is a get...TransportLayer() call for each layer that it constructs.  To insert a different layer, simply override one of these calls and wrap the default layer with the new one.

<p/>When the SocketPastryNodeFactory tries to construct the lowest layer, it calls <code>getWireTransportLayer()</code>.  We will first construct the default layer by calling super.getWireTransportLayer().  However, we will return our Bandwidth-Limiting layer that wraps the wire layer.
<pre>
  public static PastryNodeFactory exampleA(int bindport, Environment env, NodeIdFactory nidFactory, final int amt, final int time) throws IOException {    
    PastryNodeFactory factory = new SocketPastryNodeFactory(nidFactory, bindport, env) {
      @Override
      protected TransportLayer&lt;InetSocketAddress, ByteBuffer&gt; getWireTransportLayer(InetSocketAddress innermostAddress, TLPastryNode pn) throws IOException {
        // get the default layer
        TransportLayer&lt;InetSocketAddress, ByteBuffer&gt; wtl = super.getWireTransportLayer(innermostAddress, pn);        
        
        // wrap it with our layer
        return new BandwidthLimitingTransportLayer&lt;InetSocketAddress&gt;(wtl, amt, time, pn.getEnvironment());
      }      
    };
    return factory;
  } 
</pre>
<p/>You can replace the construction of the SocketPastryNodeFactory at the beginning of any of the existing tutorials with this code to add the "bandwidth-limiting" feature.  

<p/>Perhaps we don't want to include some of FreePastry's overhead in our bandwidth lmitation.  If we put it above the SourceRouteManager, we don't include bandwidth for liveness checks, nor overhead from constructing source routes.  However, the SourceRouteManager also performs additional functions of providing Liveness and Proximity.  In <code>exampleB()</code> we show how easy it is to replace only the TransportLayer functionality of the SourceRouteManager while still returning the existing TransportLayer for the Liveness and Proximity functionality.  The returned object for <code>getSourceRouteManagerLayer()</code> is a <code>TransLivenessProximity&lt;MultiInetSocketAddress, ByteBuffer&gt;<code>.  This is a very simple interface that returns 3 objects:

<pre>
  protected interface TransLivenessProximity<Identifier, MessageType&gt;> {
    TransportLayer<Identifier, ByteBuffer&gt;> getTransportLayer(); 
    LivenessProvider<Identifier&gt;> getLivenessProvider();
    ProximityProvider<Identifier&gt;> getProximityProvider();
  }
</pre>

Here is the code for exampleB():
<pre>
  public static PastryNodeFactory exampleB(int bindport, Environment env, NodeIdFactory nidFactory, final int amt, final int time) throws IOException {    
    PastryNodeFactory factory = new SocketPastryNodeFactory(nidFactory, bindport, env) {

      @Override
      protected TransLivenessProximity&lt;MultiInetSocketAddress, ByteBuffer&gt; getSourceRouteManagerLayer(
          TransportLayer&lt;SourceRoute&lt;MultiInetSocketAddress&gt;, ByteBuffer&gt; ltl, 
          LivenessProvider&lt;SourceRouteMultiInetSocketAddress&gt;&gt; livenessProvider, 
          Pinger&lt;SourceRoute&lt;MultiInetSocketAddress&gt;&gt; pinger, 
          TLPastryNode pn, 
          MultiInetSocketAddress proxyAddress, 
          MultiAddressSourceRouteFactory esrFactory) throws IOException {
        
        final TransLivenessProximity&lt;MultiInetSocketAddress, ByteBuffer&gt; srm = super.getSourceRouteManagerLayer(
            ltl, livenessProvider, pinger, pn, proxyAddress, esrFactory);
        
        final BandwidthLimitingTransportLayer bll = new BandwidthLimitingTransportLayer&lt;MultiInetSocketAddress&gt;(
            srm.getTransportLayer(), amt, time, pn.getEnvironment());
        
        return new TransLivenessProximity&lt;MultiInetSocketAddress, ByteBuffer&gt;(){
          public TransportLayer&lt;MultiInetSocketAddress, ByteBuffer&gt; getTransportLayer() {
            return bll;
          }        
          public LivenessProvider&lt;MultiInetSocketAddress&gt; getLivenessProvider() {
            return srm.getLivenessProvider();
          }
          public ProximityProvider&lt;MultiInetSocketAddress&gt; getProximityProvider() {
            return srm.getProximityProvider();
          }
        };
      }
    };
    return factory;    
  }  
</pre>

<h4>Running the code</h4>
<p/>We modified DistTutorial from <a href="">lesson4</a> to take some more parameters and call <code>BandwidthLimitingTransportLayer.exampleA()</code>.

<pre>
  public DistTutorial(int bindport, InetSocketAddress bootaddress, int numNodes, Environment env, int bandwidth) throws Exception {
    ...

    // construct the PastryNodeFactory, this is how we use rice.pastry.socket
    PastryNodeFactory factory = BandwidthLimitingTransportLayer.exampleA(bindport, env, nidFactory, bandwidth, 1000);
    //  PastryNodeFactory factory = BandwidthLimitingTransportLayer.exampleB(bindport, env, nidFactory, bandwidth, 1000);
    //  PastryNodeFactory factory = new SocketPastryNodeFactory(nidFactory, bindport, env);

    ...
  }

  /**
   * Usage: 
   * java [-cp FreePastry-&lt;version&gt;.jar] rice.tutorial.transportlayer.DistTutorial localbindport bootIP bootPort numNodes bandwidth;
   * example java rice.tutorial.transportlayer.DistTutorial 9001 pokey.cs.almamater.edu 9001 10 1000
   */
  public static void main(String[] args) throws Exception {
    ...
  }
</pre>

<p/>We need to turn on FINE logging in our transport layer, and let's also disable ProximityNeighborSelection:
<pre>
    // Disable PNS for our example
    env.getParameters().setBoolean("transport_use_pns", false);
    
    // enable logging on our new layer
    env.getParameters().setInt("rice.tutorial.transportlayer.BandwidthLimitingTransportLayer_loglevel", Logger.FINE);    
</pre>

<p/>Now lets run the code, but we must provide the bandwidth.  Let's try 10K/second:

<pre>
<span class="input">java -cp .:FreePastry-@freepastry_version@.jar rice.tutorial.transportlayer.DistTutorial 5009 10.9.8.7 5009 10 10000</span>
<span class="output">
Finished creating new node TLPastryNode[SNH: &lt;0x9492E7..&gt;/FOO/10.9.8.7:5009]
Finished creating new node TLPastryNode[SNH: &lt;0x44C3E7..&gt;/FOO/10.9.8.7:5010]
Finished creating new node TLPastryNode[SNH: &lt;0xBE1C77..&gt;/FOO/10.9.8.7:5011]
Finished creating new node TLPastryNode[SNH: &lt;0x4C94DA..&gt;/FOO/10.9.8.7:5012]
Finished creating new node TLPastryNode[SNH: &lt;0x3FAE2B..&gt;/FOO/10.9.8.7:5013]
Finished creating new node TLPastryNode[SNH: &lt;0xA5DBDC..&gt;/FOO/10.9.8.7:5014]
Finished creating new node TLPastryNode[SNH: &lt;0x99460E..&gt;/FOO/10.9.8.7:5015]
0xB5DAB7:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222632375:Limiting SM java.nio.channels.SocketChannel[connected local=/10.9.8.7:2771 remote=/10.9.8.7:5014] to 315 bytes.
0xB5DAB7:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222632390:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xB5DAB7:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222632390:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
Finished creating new node TLPastryNode[SNH: &lt;0xB5DAB7..&gt;/FOO/10.9.8.7:5016]
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634218:Limiting SM java.nio.channels.SocketChannel[connected local=/10.9.8.7:5017 remote=/10.9.8.7:2775] to 283 bytes.
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634234:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634250:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0xC3183D:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222634250:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
Finished creating new node TLPastryNode[SNH: &lt;0xC3183D..&gt;/FOO/10.9.8.7:5017]
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Limiting SM java.nio.channels.SocketChannel[connected local=/10.9.8.7:2786 remote=/10.9.8.7:5011] to 410 bytes.
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Limiting SM java.nio.channels.SocketChannel[connected local=/10.9.8.7:2789 remote=/10.9.8.7:5015] to 0 bytes.
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Limiting SM java.nio.channels.SocketChannel[connected local=/10.9.8.7:2788 remote=/10.9.8.7:5010] to 0 bytes.
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635843:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
0x317CF2:rice.tutorial.transportlayer.BandwidthLimitingTransportLayer:1190222635859:Dropping message java.nio.HeapByteBuffer[pos=0 lim=92 cap=92] because not enough bandwidth:0
Finished creating new node TLPastryNode[SNH: &lt;0x317CF2..&gt;/FOO/10.9.8.7:5018]
MyApp &lt;0x9492E7..&gt; sending to &lt;0x1CACFE..&gt;
MyApp &lt;0x317CF2..&gt; received MyMsg from &lt;0x9492E7..&gt; to &lt;0x1CACFE..&gt;

...
</span></pre>

Note the logging of 

<pre>
Limiting SM XXX to XXX bytes.
</pre>

and 

<pre>
Dropping message XXX because not enough bandwidth:XXX
</pre>

However, the code still runs successfully.

<h3>Congratulations!  You have successfully extended FreePastry's transport layer.<br>

<hr/>
<div class="nav">
  <span class="nav-left"><a href="tut_forward.html#forward">Previous (Forwarding)</a></span> 
  <span class="nav-center"><a href="index.html">Contents</a></span> 
  <span class="nav-right"><a href="tut_cancellable_msg.html">Next (Cancellable Messages)</a></span>
</div><br/>

<div class="footer">
Pastry tutorial version @tutorial_version@. &nbsp;&nbsp;&nbsp; Last updated @tutorial_date@.
&nbsp;&nbsp;&nbsp; For FreePastry @freepastry_version@. &nbsp;&nbsp;&nbsp; Maintained by @maintainer@.
</div>

</div>
</body>
</html>

